{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Створення автоматизованого продавця-консультанта"
      ],
      "metadata": {
        "id": "sxpTiDXAX9sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ПОТРІБНІ БІБЛІОТЕКИ\n",
        "\n",
        "# Бібліотека Google Generative AI для роботи з моделями Gemini\n",
        "import google.generativeai as genai\n",
        "# Для роботи з даними\n",
        "import pandas as pd\n",
        "# Для затримок між запитами до моделі\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "NJowpG2mI7Px"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ініціалізація API-ключа для Gemini\n",
        "GEMINI_API_KEY = \"AIzaSyD9NQABKTJLhtpAcGuUGU1ki4ChGFzNJlw\"\n",
        "\n",
        "# Передаємо API-ключ для конфігурації підключення до сервісу\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# --- 1. Створення автоматизованого продавця-консультанта ---\n",
        "def chatbot_response(user_input, messages):\n",
        "    \"\"\"\n",
        "    Функція отримує відповідь від бота на основі введеного тексту користувача.\n",
        "    \"\"\"\n",
        "    # Додаємо нове повідомлення від користувача (роль 'user') в історію\n",
        "    messages.append({'role': 'user', 'content': user_input})\n",
        "\n",
        "    # Створюємо об'єкт моделі Gemini для генерації відповіді\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    try:\n",
        "        # Генеруємо відповідь на основі запиту користувача\n",
        "        response = model.generate_content(\n",
        "            contents=[{'role': 'user', 'parts': [{'text': user_input}]}],  # Відправляємо запит з текстом користувача\n",
        "            generation_config=genai.types.GenerationConfig(  # Налаштовуємо параметри генерації відповіді\n",
        "                candidate_count=1,    # Генеруємо лише одну відповідь\n",
        "                temperature=1.0,      # Встановлюємо високу креативність\n",
        "                max_output_tokens=50  # Контроль довжини відповіді (максимум 50). Відповідь буде коротка і по суті\n",
        "            )                         # Токен — це базовий елемент тексту, який модель обробляє\n",
        "        )\n",
        "\n",
        "        # Додаємо відповідь бота до історії\n",
        "        messages.append({'role': 'assistant', 'content': response.text})\n",
        "        return response.text, messages  # Повертаємо текст відповіді і оновлену історію\n",
        "    except Exception as e:\n",
        "        # У разі помилки повертаємо текст помилки\n",
        "        return f\"Error: {e}\", messages\n",
        "\n",
        "# --- 2. Функція для аналізу відгуків ---\n",
        "def analyze_reviews(reviews, category):\n",
        "    \"\"\"\n",
        "    Функція аналізує текстові відгуки за заданою категорією.\n",
        "    \"\"\"\n",
        "    results = []  # Ініціалізуємо список для збереження результатів аналізу\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')  # Використовуємо модель Gemini\n",
        "    for review in reviews:  # Проходимо по кожному відгуку в списку\n",
        "        prompt = f\"Проаналізуйте відгук за категорією '{category}': {review}\"  # Формуємо текст запиту для аналізу\n",
        "        try:\n",
        "            # Генеруємо відповідь на запит\n",
        "            response = model.generate_content(\n",
        "                contents=[{'role': 'user', 'parts': [{'text': prompt}]}],  # Передаємо текст для обробки\n",
        "                generation_config=genai.types.GenerationConfig(  # Налаштовуємо генерацію\n",
        "                    candidate_count=1,  # Генеруємо одну відповідь\n",
        "                    temperature=0.7,    # Температура для балансу між випадковістю та точністю\n",
        "                    max_output_tokens=50  # Обмеження на кількість токенів у відповіді\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Додаємо відповідь до списку результатів\n",
        "            results.append(response.text)\n",
        "            sleep(1)  # Робимо затримку у 1 секунду для уникнення перевантаження API\n",
        "        except Exception as e:\n",
        "            results.append(f\"Error: {e}\")  # Якщо сталася помилка, додаємо її до списку результатів\n",
        "    return results  # Повертаємо список результатів аналізу\n",
        "\n",
        "# --- 3. Тестування параметра temperature ---\n",
        "def test_temperature(prompt):\n",
        "    \"\"\"\n",
        "    Демонструє вплив параметра temperature на характер відповіді.\n",
        "    \"\"\"\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')  # Вибираємо модель Gemini 1.5 flash\n",
        "\n",
        "    # Цикл для перевірки трьох різних значень temperature (характеру відповідей)\n",
        "    for temp in [0.2, 0.7, 1.0]:\n",
        "        try:\n",
        "            # Генеруємо відповідь для кожного значення температури\n",
        "            response = model.generate_content(\n",
        "                contents=[{'role': 'user', 'parts': [{'text': prompt}]}],  # Передаємо текст запиту\n",
        "                generation_config=genai.types.GenerationConfig(  # Налаштовуємо параметри генерації\n",
        "                    candidate_count=1,    # Генеруємо одну відповідь\n",
        "                    temperature=temp,     # Змінюємо температуру для тестування\n",
        "                    max_output_tokens=50  # Максимальна кількість токенів\n",
        "                )\n",
        "            )\n",
        "            # Виводимо відповідь для кожної температури (тональності)\n",
        "            print(f\"Temperature {temp}:\\n{response.text}\\n\")\n",
        "        except Exception as e:\n",
        "            # Обробка помилок при тестуванні температури\n",
        "            print(f\"Temperature {temp}: Error: {e}\")\n",
        "\n",
        "# --- Основна функція ---\n",
        "def main():\n",
        "    # --- 1. Робота з чат-ботом ---\n",
        "\n",
        "    # Передає інформацію моделі про те, який тон або контекст слід підтримувати.\n",
        "    messages = [{'role': 'system', 'content': 'You are a helpful assistant. How can I assist you with your shopping needs?'}]\n",
        "    print(\"Bot: Hello! How can I assist you today?\\n\")  # Виводимо початкову відповідь бота\n",
        "\n",
        "    # Цикл для безперервної роботи бота\n",
        "    while True:\n",
        "        print(\"\\nEnter [exit] to stop the conversation.\")  # Повідомляємо, що можна вийти\n",
        "        user_input = input(\"You: \")  # Отримуємо запит від користувача\n",
        "        if user_input.lower() in [\"exit\"]:  # Перевіряємо, чи користувач хоче завершити бесіду\n",
        "            print(\"Bot: Goodbye! Have a great day!\")  # Прощаємося з користувачем\n",
        "            break  # Завершуємо цикл\n",
        "        response, messages = chatbot_response(user_input, messages)  # Отримуємо відповідь від бота\n",
        "        print(f\"Bot: {response}\")  # Виводимо відповідь бота\n",
        "\n",
        "    # 2. Аналіз відгуків\n",
        "    print(\"\\n--- Review Analysis ---\")  # Виводимо заголовок для аналізу відгуків\n",
        "    filename = \"Womens Clothing E-Commerce Reviews.csv\"  # Вказуємо файл з відгуками\n",
        "\n",
        "    # Цикл аналізу відгуків: завантаження даних, фільтрація, аналіз і обробка помилок\n",
        "    try:\n",
        "        # Завантажуємо файл і прибираємо пропуски в потрібних стовпцях\n",
        "        df = pd.read_csv(filename).dropna(subset=['Review Text'])\n",
        "        df = df.head(100)  # Обмежуємо дані до перших 100 записів\n",
        "        # Перетворюємо стовпець з відгуками в список, щоб спростити подальшу роботу з даними\n",
        "        reviews = df['Review Text'].tolist()\n",
        "        # Аналіз за обраною категорією\n",
        "        category = \"Satisfaction with Quality\"  # Вказуємо категорію для аналізу\n",
        "        results = analyze_reviews(reviews[:10], category)  # Аналізуємо перші 10 відгуків\n",
        "\n",
        "        # Виводимо результати для кожного відгуку\n",
        "        for i, result in enumerate(results, 1):\n",
        "            print(f\"Review {i}: {result}\")\n",
        "    # Якщо файл не знайдено, виводимо повідомлення про помилку\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Please upload 'Womens Clothing E-Commerce Reviews.csv'.\")\n",
        "\n",
        "    # 3. Тестування параметра temperature\n",
        "    print(\"\\n--- Testing Temperature ---\")  # Виводимо заголовок для тестування температури\n",
        "    test_prompt = \"What clothing would you recommend for an office?\"  # Запит для тестування\n",
        "    test_temperature(test_prompt)  # Викликаємо функцію тестування температури\n",
        "\n",
        "# Запуск основної функції\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zv02aZ7quysi",
        "outputId": "1be671f9-05aa-4bf7-b6d8-629ca22a6ee1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: Hello! How can I assist you today?\n",
            "\n",
            "\n",
            "Enter [exit] to stop the conversation.\n",
            "You: Hi\n",
            "Bot: Hi there! How can I help you today?\n",
            "\n",
            "\n",
            "Enter [exit] to stop the conversation.\n",
            "You: Привіт\n",
            "Bot: Привіт!\n",
            "\n",
            "\n",
            "Enter [exit] to stop the conversation.\n",
            "You: Ти знаєш скільки мов?\n",
            "Bot: Я можу обробляти та генерувати текст більш ніж 100 мовами.  Однак, я не \"знаю\" мови в тому ж сенсі, як це робить людина. Я не маю\n",
            "\n",
            "Enter [exit] to stop the conversation.\n",
            "You: Який одяг отримав найбільше позитивних відгуків?\n",
            "Bot: Я не маю доступу до реального часу даних, включаючи відгуки про одяг. Щоб дізнатися, який одяг отримав найбільше позитивних відгуків, потрібно вказати джерело\n",
            "\n",
            "Enter [exit] to stop the conversation.\n",
            "You: Що ви порадите для вечірки?\n",
            "Bot: Щоб порадити вам щось для вечірки, мені потрібно знати більше деталей!  Розкажіть мені:\n",
            "\n",
            "* **Який тип вечірки?** (День народження, новорічна, тематична, корпора\n",
            "\n",
            "Enter [exit] to stop the conversation.\n",
            "You: What do you recommend for a first date?\n",
            "Bot: The best first date depends heavily on the individuals involved and their interests, but here are some ideas categorized by preference, with considerations for each:\n",
            "\n",
            "**Low-Pressure, Get-to-Know-You Options:**\n",
            "\n",
            "* **Coffee Date:** Casual\n",
            "\n",
            "Enter [exit] to stop the conversation.\n",
            "You: Які товари подобаються покупцям віком 40+?\n",
            "Bot: Покупці віком 40+ є досить різноманітною групою, тому їхні уподобання залежать від багатьох факторів, таких як стать, сімейний стан, рівень до\n",
            "\n",
            "Enter [exit] to stop the conversation.\n",
            "You: exit\n",
            "Bot: Goodbye! Have a great day!\n",
            "\n",
            "--- Review Analysis ---\n",
            "Review 1: Відгук \"Absolutely wonderful - silky and sexy and comfortable\"  в категорії \"Satisfaction with Quality\" вказує на **дуже високий рівень задоволення**.  Оцінка позитивна за всіма трьо\n",
            "Review 2: The review expresses high satisfaction with the quality (\"Love this dress! it's sooo pretty\").  The positive sentiment is strong and unambiguous.  While the reviewer mentions the petite sizing, this is framed positively – it highlights a fortunate in-store discovery\n",
            "Review 3: This review expresses **low satisfaction with quality**.  While the customer initially liked the *idea* of the dress, the execution fell short.  Here's a breakdown:\n",
            "\n",
            "* **Sizing Issues:** The major complaint is the inaccurate sizing.  \n",
            "Review 4: Цей відгук висловлює **дуже високий рівень задоволення** якістю (Satisfaction with Quality).  Хоча він не описує конкретні аспекти якості (наприклад, матеріал, пошиття,\n",
            "Review 5: The review expresses high satisfaction with the quality, albeit indirectly.  It doesn't explicitly mention fabric quality, stitching, or durability. Instead, the satisfaction stems from the garment's:\n",
            "\n",
            "* **Design and Fit:** The adjustable front tie is\n",
            "Review 6: This review expresses **dissatisfaction** with the quality in the context of fit and suitability for the reviewer's body type.  While praising the dress's inherent beauty (\"very pretty out of the package,\" \"love the color and the idea of\n",
            "Review 7: The customer's review expresses a high degree of satisfaction with the quality of the item, specifically focusing on the color and its versatility.  Here's a breakdown:\n",
            "\n",
            "**Positive Aspects:**\n",
            "\n",
            "* **Color:** The customer explicitly states the color\n",
            "Review 8: Error: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
            "Review 9: The review expresses high satisfaction with the quality.  The phrasing \"I love this dress\" is a strong indicator of positive sentiment. While the reviewer mentions needing to size up due to a snug bust, this is presented not as a fault of quality but\n",
            "Review 10: The review expresses high satisfaction with the quality, albeit indirectly.  The customer focuses on the fit and versatility of the dress, which are strong indicators of quality.  Here's a breakdown:\n",
            "\n",
            "* **Positive Aspects:** The customer explicitly states \"\n",
            "\n",
            "--- Testing Temperature ---\n",
            "Temperature 0.2:\n",
            "The best office clothing depends heavily on the office culture.  However, here's a breakdown of options ranging from most formal to most casual, with suggestions for each:\n",
            "\n",
            "**Formal Office (Law firm, finance, etc.):**\n",
            "\n",
            "* **\n",
            "\n",
            "Temperature 0.7:\n",
            "The best office clothing depends heavily on the office culture.  However, here's a breakdown of options for different office environments, ranging from most formal to most casual:\n",
            "\n",
            "**Formal Office (Law firm, finance, etc.):**\n",
            "\n",
            "* **\n",
            "\n",
            "Temperature 1.0:\n",
            "The best office clothing depends heavily on the office culture.  To give you the best recommendations, I need more information.  However, here are some suggestions based on different office environments:\n",
            "\n",
            "**For a Business Formal Office:**\n",
            "\n",
            "* **Men:**\n",
            "\n"
          ]
        }
      ]
    }
  ]
}